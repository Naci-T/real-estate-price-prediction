{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "df69615e-5b2d-4ccc-b46d-bd63cef016db",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import requests\n",
    "import bs4\n",
    "import json\n",
    "import pandas as pd\n",
    "import time\n",
    "\n",
    "from time import sleep\n",
    "\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.firefox.options import Options\n",
    "\n",
    "from threading import Thread"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5895c892-039f-4258-8c5a-8a7ea66ecaa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#we will use 2 hreads, one to scrape the house section and one the apprtment sections\n",
    "#this will speed up the process, and those 2 lists will make sure there are no data races\n",
    "all_links_house = []\n",
    "all_links_appartment = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "810a067e-d91a-4a8e-9db1-578301b55cbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_html(link):\n",
    "    \"\"\"\n",
    "    input : a link\n",
    "    return the html code (with javascript) of the page \n",
    "    \"\"\"\n",
    "    #!!!!!manage cookies!!!!!!!\n",
    "    path = r'C:\\Users\\Sacha\\Documents\\BeCode\\geckodriver-v0.32.0-win32\\geckodriver.exe' #to be change for diff computers\n",
    "    c = Options()\n",
    "    c.add_argument(\"--headless\")  #  faire fonctionner headless!!!!!!!!!!!!!!!!!!!!\n",
    "    \n",
    "    driver = webdriver.Firefox(executable_path = path, options=c )\n",
    "    driver.get(link)\n",
    "    \n",
    "    html = driver.page_source;\n",
    "    \n",
    "    driver.close()\n",
    "    \n",
    "    return html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9a0d6b29-7daf-4ec9-87ff-cb78b30fec5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_link_from_html(html):\n",
    "    \"\"\"\n",
    "    input: an html content\n",
    "    scrape the html content to get tthe links of the house/appartment cards of that pag\n",
    "    return a list with those links\n",
    "    \"\"\"\n",
    "    temp = []\n",
    "    soup = bs4.BeautifulSoup(html, \"html.parser\")\n",
    "    for card in soup.find_all(\"a\", class_=\"card__title-link\"):\n",
    "        temp.append(card['href'])\n",
    "    return temp\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "77784c6e-22d5-4ff6-add3-a6397aa8dc1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_link_house(base_house_link, end_link, start, end):\n",
    "    \"\"\"\n",
    "    input: base_house_link/ end_link = part of a link\n",
    "           start/end = integer representing the start and the end of a loop\n",
    "    returns all the links for houses between pages start and end\n",
    "    \"\"\"\n",
    "    global all_links_house\n",
    "    for i in range (start,end):\n",
    "        print(\"house, page\",i)\n",
    "        link = base_house_link + str(i) + end_link\n",
    "        html = get_html(link)\n",
    "        all_links_house.extend(get_link_from_html(html))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7ee6533a-d605-46ec-8867-c805389af2b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_link_appartment(base_appartment_link, end_link, start, end):\n",
    "    \"\"\"\n",
    "    input: base_house_link/ end_link = part of a link\n",
    "           start/end = integer representing the start and the end of a loop\n",
    "    returns all the links forappartment between pages start and end\n",
    "    \"\"\"\n",
    "    global all_links_appartment\n",
    "    for i in range (start,end):\n",
    "        print(\"appart, page\",i)\n",
    "        link = base_appartment_link + str(i) + end_link\n",
    "        html = get_html(link)\n",
    "        all_links_appartment.extend(get_link_from_html(html))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "74175f92-cab4-4746-8242-a853be56da1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_all_links():\n",
    "    \"\"\"\n",
    "    this function scrape immoweb to get all the links of appartments and houses to sale in belgium, and it saves it\n",
    "    \"\"\"\n",
    "    start = time.time()\n",
    "    base_house_link = \"https://www.immoweb.be/en/search/house/for-sale?countries=BE&page=\"\n",
    "    base_appartment_link = \"https://www.immoweb.be/en/search/apartment/for-sale?countries=BE&page=\"\n",
    "    num = \"0\"\n",
    "    end_link = \"&orderBy=relevance\"\n",
    "    \n",
    "    all_links = []\n",
    "    \n",
    "    \"\"\"\n",
    "    #at first, we will take every link in the house section\n",
    "    for i in range (1,334):\n",
    "        print(\"house, page\",i)\n",
    "        link = base_house_link + str(i) + end_link\n",
    "        html = get_html(link)\n",
    "        all_links.extend(get_link_from_html(html))\n",
    "        \n",
    "    #then we will take all the link in the appartment section\n",
    "    for i in range (1,334):\n",
    "        print(\"appartment, page\",i)\n",
    "        link = base_appartment_link + str(i) + end_link\n",
    "        html = get_html(link)\n",
    "        all_links.extend(get_link_from_html(html))\n",
    "    \"\"\"\n",
    "    \n",
    "    ##################################### with concurrency #############################################\n",
    "    threads = list()\n",
    "    \n",
    "    #at first, we will take every link in the house section\n",
    "    thread = Thread(target=get_link_house, args=(base_house_link, end_link, 1, 334, )) \n",
    "    threads.append(thread) \n",
    "    #then, we will take every link in the appartment section\n",
    "    thread = Thread(target=get_link_appartment, args=(base_appartment_link, end_link, 1, 334, )) \n",
    "    threads.append(thread) \n",
    "    \n",
    "    for thread in threads:\n",
    "        thread.start()\n",
    "    for thread in threads:  \n",
    "        thread.join()\n",
    "        \n",
    "    all_links.extend(all_links_house)\n",
    "    all_links.extend(all_links_appartment)\n",
    "    ################################################################################################\n",
    "    \n",
    "    df = pd.DataFrame(all_links) #all_links is a list of 1 list\n",
    "    unique_links_df = df.duplicated(keep='first')\n",
    "    df = df[~unique_links_df]       #delete the duplicates\n",
    "    \n",
    "    print(\"num duplicates\",unique_links_df.sum())\n",
    "    #print(df.iloc[0,0])\n",
    "    print(\"size\",df.size)\n",
    "    \n",
    "    df.to_csv('links.csv')\n",
    "    end = time.time()\n",
    "    print(\"done\", end-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7324b195-815a-42b5-814e-945501f91327",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_all_links()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
